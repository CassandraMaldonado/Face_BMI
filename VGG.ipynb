{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mtcnn\n",
      "  Downloading mtcnn-1.0.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: joblib>=1.4.2 in /opt/anaconda3/lib/python3.12/site-packages (from mtcnn) (1.4.2)\n",
      "Collecting lz4>=4.3.3 (from mtcnn)\n",
      "  Downloading lz4-4.4.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Downloading mtcnn-1.0.0-py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading lz4-4.4.4-cp312-cp312-macosx_11_0_arm64.whl (189 kB)\n",
      "Installing collected packages: lz4, mtcnn\n",
      "  Attempting uninstall: lz4\n",
      "    Found existing installation: lz4 4.3.2\n",
      "    Uninstalling lz4-4.3.2:\n",
      "      Successfully uninstalled lz4-4.3.2\n",
      "Successfully installed lz4-4.4.4 mtcnn-1.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install mtcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras_vggface in /opt/anaconda3/lib/python3.12/site-packages (0.6)\n",
      "Requirement already satisfied: keras_applications in /opt/anaconda3/lib/python3.12/site-packages (1.0.8)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/anaconda3/lib/python3.12/site-packages (from keras_vggface) (1.26.4)\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/anaconda3/lib/python3.12/site-packages (from keras_vggface) (1.13.1)\n",
      "Requirement already satisfied: h5py in /opt/anaconda3/lib/python3.12/site-packages (from keras_vggface) (3.11.0)\n",
      "Requirement already satisfied: pillow in /opt/anaconda3/lib/python3.12/site-packages (from keras_vggface) (11.1.0)\n",
      "Requirement already satisfied: keras in /opt/anaconda3/lib/python3.12/site-packages (from keras_vggface) (3.8.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from keras_vggface) (1.16.0)\n",
      "Requirement already satisfied: pyyaml in /opt/anaconda3/lib/python3.12/site-packages (from keras_vggface) (6.0.1)\n",
      "Requirement already satisfied: absl-py in /opt/anaconda3/lib/python3.12/site-packages (from keras->keras_vggface) (2.1.0)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/lib/python3.12/site-packages (from keras->keras_vggface) (13.7.1)\n",
      "Requirement already satisfied: namex in /opt/anaconda3/lib/python3.12/site-packages (from keras->keras_vggface) (0.0.8)\n",
      "Requirement already satisfied: optree in /opt/anaconda3/lib/python3.12/site-packages (from keras->keras_vggface) (0.14.0)\n",
      "Requirement already satisfied: ml-dtypes in /opt/anaconda3/lib/python3.12/site-packages (from keras->keras_vggface) (0.4.1)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from keras->keras_vggface) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from optree->keras->keras_vggface) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->keras->keras_vggface) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->keras->keras_vggface) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras->keras_vggface) (0.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install keras_vggface keras_applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.19.0-cp312-cp312-macosx_12_0_arm64.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: keras-applications in /opt/anaconda3/lib/python3.12/site-packages (1.0.8)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (75.9.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.69.0)\n",
      "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Downloading keras-3.9.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.11.0)\n",
      "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.5.1-cp312-cp312-macosx_10_9_universal2.whl.metadata (21 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in /opt/anaconda3/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /opt/anaconda3/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Downloading tensorflow-2.19.0-cp312-cp312-macosx_12_0_arm64.whl (252.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.7/252.7 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.9.2-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.5.1-cp312-cp312-macosx_10_9_universal2.whl (670 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.4/670.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: ml-dtypes, tensorboard, keras, tensorflow\n",
      "  Attempting uninstall: ml-dtypes\n",
      "    Found existing installation: ml-dtypes 0.4.1\n",
      "    Uninstalling ml-dtypes-0.4.1:\n",
      "      Successfully uninstalled ml-dtypes-0.4.1\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.18.0\n",
      "    Uninstalling tensorboard-2.18.0:\n",
      "      Successfully uninstalled tensorboard-2.18.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.19.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed keras-3.9.2 ml-dtypes-0.5.1 tensorboard-2.19.0 tensorflow-2.19.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting git+https://github.com/rcmalli/keras-vggface.git\n",
      "  Cloning https://github.com/rcmalli/keras-vggface.git to /private/var/folders/4g/7cwxt52n09sb7vzyh6tzj3w00000gn/T/pip-req-build-p3s0z65c\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/rcmalli/keras-vggface.git /private/var/folders/4g/7cwxt52n09sb7vzyh6tzj3w00000gn/T/pip-req-build-p3s0z65c\n",
      "  Resolved https://github.com/rcmalli/keras-vggface.git to commit bee35376e76e35d00aeec503f2f242611a97b38a\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /opt/anaconda3/lib/python3.12/site-packages (from keras_vggface==0.6) (1.26.4)\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/anaconda3/lib/python3.12/site-packages (from keras_vggface==0.6) (1.13.1)\n",
      "Requirement already satisfied: h5py in /opt/anaconda3/lib/python3.12/site-packages (from keras_vggface==0.6) (3.11.0)\n",
      "Requirement already satisfied: pillow in /opt/anaconda3/lib/python3.12/site-packages (from keras_vggface==0.6) (11.1.0)\n",
      "Requirement already satisfied: keras in /opt/anaconda3/lib/python3.12/site-packages (from keras_vggface==0.6) (3.9.2)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from keras_vggface==0.6) (1.16.0)\n",
      "Requirement already satisfied: pyyaml in /opt/anaconda3/lib/python3.12/site-packages (from keras_vggface==0.6) (6.0.1)\n",
      "Requirement already satisfied: absl-py in /opt/anaconda3/lib/python3.12/site-packages (from keras->keras_vggface==0.6) (2.1.0)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/lib/python3.12/site-packages (from keras->keras_vggface==0.6) (13.7.1)\n",
      "Requirement already satisfied: namex in /opt/anaconda3/lib/python3.12/site-packages (from keras->keras_vggface==0.6) (0.0.8)\n",
      "Requirement already satisfied: optree in /opt/anaconda3/lib/python3.12/site-packages (from keras->keras_vggface==0.6) (0.14.0)\n",
      "Requirement already satisfied: ml-dtypes in /opt/anaconda3/lib/python3.12/site-packages (from keras->keras_vggface==0.6) (0.5.1)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from keras->keras_vggface==0.6) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from optree->keras->keras_vggface==0.6) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->keras->keras_vggface==0.6) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->keras->keras_vggface==0.6) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras->keras_vggface==0.6) (0.1.0)\n",
      "Building wheels for collected packages: keras_vggface\n",
      "  Building wheel for keras_vggface (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras_vggface: filename=keras_vggface-0.6-py3-none-any.whl size=8345 sha256=d497fd0d1e24896abc28fa6fb73cdcc9c0188ee36798462c0f60e62ce3b6d9f8\n",
      "  Stored in directory: /private/var/folders/4g/7cwxt52n09sb7vzyh6tzj3w00000gn/T/pip-ephem-wheel-cache-zeaesria/wheels/24/2b/7a/ef35f1e8c2a0ba6dd6d680eecd50522759b6e4b6170b700084\n",
      "Successfully built keras_vggface\n",
      "Installing collected packages: keras_vggface\n",
      "Successfully installed keras_vggface-0.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow keras-applications\n",
    "%pip install git+https://github.com/rcmalli/keras-vggface.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BMI Prediction API using VGG-Face model\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from flask import Flask, request, jsonify, render_template\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from mtcnn import MTCNN\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'layer_utils' from 'keras.utils' (/opt/anaconda3/lib/python3.12/site-packages/keras/api/utils/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Import our custom VGGFace implementation\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_vggface\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvggface\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VGGFace\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_vggface\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m preprocess_input\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Initialize Flask app\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras_vggface/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_vggface\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvggface\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VGGFace\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_vggface\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras_vggface/vggface.py:9\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m'''VGGFace models for Keras.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m# Reference:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m print_function\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_vggface\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RESNET50, VGG16, SENET50\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mVGGFace\u001b[39m(include_top\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvgg16\u001b[39m\u001b[38;5;124m'\u001b[39m, weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvggface\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     13\u001b[0m             input_tensor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, input_shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     14\u001b[0m             pooling\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     15\u001b[0m             classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     16\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Instantiates the VGGFace architectures.\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m    Optionally loads weights pre-trained\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m    on VGGFace datasets. Note that when using TensorFlow,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m            or invalid input shape.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras_vggface/models.py:16\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Flatten, Dense, Input, GlobalAveragePooling2D, \\\n\u001b[1;32m     13\u001b[0m     GlobalMaxPooling2D, Activation, Conv2D, MaxPooling2D, BatchNormalization, \\\n\u001b[1;32m     14\u001b[0m     AveragePooling2D, Reshape, Permute, multiply\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_applications\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimagenet_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _obtain_input_shape\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layer_utils\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_file\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend \u001b[38;5;28;01mas\u001b[39;00m K\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'layer_utils' from 'keras.utils' (/opt/anaconda3/lib/python3.12/site-packages/keras/api/utils/__init__.py)"
     ]
    }
   ],
   "source": [
    "# Import our custom VGGFace implementation\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from keras_vggface.utils import preprocess_input\n",
    "\n",
    "# Initialize Flask app\n",
    "app = Flask(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up paths\n",
    "DATA_PATH = \"data.csv\"\n",
    "IMAGE_PATH = \"images\"\n",
    "MODEL_PATH = \"bmi_predictor_model.h5\"\n",
    "\n",
    "# Initialize face detector\n",
    "detector = MTCNN()\n",
    "\n",
    "# Define image size (VGG-Face input size)\n",
    "IMAGE_SIZE = (224, 224)\n",
    "\n",
    "# Function to load and preprocess the dataset\n",
    "def load_data(data_path, image_folder):\n",
    "    \"\"\"Load data from CSV and preprocess images\"\"\"\n",
    "    # Read the data.csv file\n",
    "    df = pd.read_csv(data_path)\n",
    "    \n",
    "    # Initialize arrays for features and labels\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        image_path = os.path.join(image_folder, row['name'])\n",
    "        \n",
    "        # Check if image exists\n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"Warning: Image {image_path} not found\")\n",
    "            continue\n",
    "        \n",
    "        # Load and preprocess image\n",
    "        img = preprocess_face_image(image_path)\n",
    "        if img is not None:\n",
    "            X.append(img)\n",
    "            y.append(row['bmi'])\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Function to detect and preprocess face in an image\n",
    "def preprocess_face_image(image_path, method='mtcnn'):\n",
    "    \"\"\"Detect face in image and preprocess it for VGG-Face\"\"\"\n",
    "    try:\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            print(f\"Error loading image: {image_path}\")\n",
    "            return None\n",
    "        \n",
    "        # Convert BGR to RGB (VGG-Face expects RGB)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if method == 'mtcnn':\n",
    "            # Use MTCNN for face detection\n",
    "            faces = detector.detect_faces(img)\n",
    "            if not faces:\n",
    "                print(f\"No face detected in {image_path}\")\n",
    "                return None\n",
    "            \n",
    "            # Get the largest face\n",
    "            face = max(faces, key=lambda x: x['box'][2] * x['box'][3])\n",
    "            x, y, w, h = face['box']\n",
    "            face_img = img[y:y+h, x:x+w]\n",
    "            \n",
    "        else:\n",
    "            # Use the entire image if not using MTCNN\n",
    "            face_img = img\n",
    "        \n",
    "        # Resize image to the required size for VGG-Face\n",
    "        face_img = cv2.resize(face_img, IMAGE_SIZE)\n",
    "        \n",
    "        # Preprocess for VGG-Face\n",
    "        face_img = preprocess_input(face_img, version=1)\n",
    "        \n",
    "        return face_img\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image {image_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Function to preprocess base64 image\n",
    "def preprocess_base64_image(base64_string):\n",
    "    \"\"\"Process base64 image for prediction\"\"\"\n",
    "    try:\n",
    "        # Decode base64 string\n",
    "        img_data = base64.b64decode(base64_string)\n",
    "        img = Image.open(BytesIO(img_data))\n",
    "        img = np.array(img)\n",
    "        \n",
    "        # Convert to RGB if needed\n",
    "        if len(img.shape) == 2:  # Grayscale\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "        elif img.shape[2] == 4:  # RGBA\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_RGBA2RGB)\n",
    "        \n",
    "        # Detect face using MTCNN\n",
    "        faces = detector.detect_faces(img)\n",
    "        if not faces:\n",
    "            print(\"No face detected in the image\")\n",
    "            # Use the entire image if no face is detected\n",
    "            face_img = cv2.resize(img, IMAGE_SIZE)\n",
    "        else:\n",
    "            # Get the largest face\n",
    "            face = max(faces, key=lambda x: x['box'][2] * x['box'][3])\n",
    "            x, y, w, h = face['box']\n",
    "            face_img = img[y:y+h, x:x+w]\n",
    "            face_img = cv2.resize(face_img, IMAGE_SIZE)\n",
    "        \n",
    "        # Preprocess for VGG-Face\n",
    "        face_img = preprocess_input(face_img, version=1)\n",
    "        \n",
    "        return np.expand_dims(face_img, axis=0)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing base64 image: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Function to create the VGG-Face model for BMI prediction\n",
    "def create_model():\n",
    "    \"\"\"Create and compile the VGG-Face model for BMI prediction\"\"\"\n",
    "    # Load VGG-Face model with pre-trained weights\n",
    "    base_model = VGGFace(include_top=False, input_shape=(224, 224, 3))\n",
    "    \n",
    "    # Freeze the base model layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # Add custom regression layers\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(1, activation='linear')(x)  # BMI is a continuous value\n",
    "    \n",
    "    # Create the model\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Function to train the model\n",
    "def train_model(X, y, model, epochs=50, batch_size=4, validation_split=0.2):\n",
    "    \"\"\"Train the model with the dataset\"\"\"\n",
    "    history = model.fit(\n",
    "        X, y,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=validation_split,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    return history\n",
    "\n",
    "# Function to save model training history as a plot\n",
    "def save_training_plot(history):\n",
    "    \"\"\"Save the training history as a plot\"\"\"\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    # Plot training & validation loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "    \n",
    "    # Plot training & validation mean absolute error\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['mae'])\n",
    "    plt.plot(history.history['val_mae'])\n",
    "    plt.title('Model Mean Absolute Error')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history.png')\n",
    "\n",
    "# Function to predict BMI from an image\n",
    "def predict_bmi(model, image):\n",
    "    \"\"\"Predict BMI from a preprocessed image\"\"\"\n",
    "    prediction = model.predict(image)\n",
    "    return prediction[0][0]\n",
    "\n",
    "# Create HTML templates\n",
    "def create_templates():\n",
    "    \"\"\"Create HTML templates for the web interface\"\"\"\n",
    "    os.makedirs('templates', exist_ok=True)\n",
    "    \n",
    "    # Create index.html\n",
    "    with open('templates/index.html', 'w') as f:\n",
    "        f.write('''\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <title>BMI Prediction from Face Image</title>\n",
    "    <style>\n",
    "        body {\n",
    "            font-family: Arial, sans-serif;\n",
    "            max-width: 800px;\n",
    "            margin: 0 auto;\n",
    "            padding: 20px;\n",
    "        }\n",
    "        .container {\n",
    "            display: flex;\n",
    "            flex-direction: column;\n",
    "            align-items: center;\n",
    "        }\n",
    "        .upload-area {\n",
    "            border: 2px dashed #ccc;\n",
    "            border-radius: 5px;\n",
    "            padding: 20px;\n",
    "            text-align: center;\n",
    "            margin-bottom: 20px;\n",
    "            width: 100%;\n",
    "        }\n",
    "        .webcam-area {\n",
    "            margin-top: 30px;\n",
    "            padding: 20px;\n",
    "            border: 1px solid #eee;\n",
    "            border-radius: 5px;\n",
    "            width: 100%;\n",
    "        }\n",
    "        #results {\n",
    "            margin-top: 20px;\n",
    "            padding: 20px;\n",
    "            border: 1px solid #eee;\n",
    "            border-radius: 5px;\n",
    "            display: none;\n",
    "        }\n",
    "        #videoElement {\n",
    "            width: 100%;\n",
    "            max-width: 400px;\n",
    "            border-radius: 5px;\n",
    "        }\n",
    "        button {\n",
    "            background-color: #4CAF50;\n",
    "            color: white;\n",
    "            border: none;\n",
    "            padding: 10px 20px;\n",
    "            text-align: center;\n",
    "            text-decoration: none;\n",
    "            display: inline-block;\n",
    "            font-size: 16px;\n",
    "            margin: 10px 2px;\n",
    "            cursor: pointer;\n",
    "            border-radius: 5px;\n",
    "        }\n",
    "        #preview {\n",
    "            max-width: 400px;\n",
    "            max-height: 300px;\n",
    "            margin-top: 10px;\n",
    "        }\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"container\">\n",
    "        <h1>BMI Prediction from Face Image</h1>\n",
    "        \n",
    "        <div class=\"upload-area\">\n",
    "            <h2>Upload Image</h2>\n",
    "            <input type=\"file\" id=\"fileInput\" accept=\"image/*\">\n",
    "            <p>or drag and drop image here</p>\n",
    "            <img id=\"preview\" style=\"display: none;\">\n",
    "            <button id=\"uploadButton\">Predict BMI</button>\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"webcam-area\">\n",
    "            <h2>Use Webcam</h2>\n",
    "            <p>Allow camera access to use this feature</p>\n",
    "            <video autoplay=\"true\" id=\"videoElement\"></video>\n",
    "            <div>\n",
    "                <button id=\"captureButton\">Capture</button>\n",
    "                <button id=\"predictButton\" disabled>Predict BMI</button>\n",
    "            </div>\n",
    "            <canvas id=\"canvas\" style=\"display: none;\"></canvas>\n",
    "        </div>\n",
    "        \n",
    "        <div id=\"results\">\n",
    "            <h2>Prediction Results</h2>\n",
    "            <p>Estimated BMI: <span id=\"bmiValue\">--</span></p>\n",
    "            <p>BMI Category: <span id=\"bmiCategory\">--</span></p>\n",
    "            <div id=\"bmiInfo\"></div>\n",
    "        </div>\n",
    "    </div>\n",
    "    \n",
    "    <script>\n",
    "        // Variables to store images\n",
    "        let capturedImage = null;\n",
    "        let uploadedImage = null;\n",
    "        \n",
    "        // Elements\n",
    "        const fileInput = document.getElementById('fileInput');\n",
    "        const preview = document.getElementById('preview');\n",
    "        const uploadButton = document.getElementById('uploadButton');\n",
    "        const video = document.getElementById('videoElement');\n",
    "        const captureButton = document.getElementById('captureButton');\n",
    "        const predictButton = document.getElementById('predictButton');\n",
    "        const canvas = document.getElementById('canvas');\n",
    "        const results = document.getElementById('results');\n",
    "        const bmiValue = document.getElementById('bmiValue');\n",
    "        const bmiCategory = document.getElementById('bmiCategory');\n",
    "        const bmiInfo = document.getElementById('bmiInfo');\n",
    "        \n",
    "        // Initialize webcam\n",
    "        if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {\n",
    "            navigator.mediaDevices.getUserMedia({ video: true })\n",
    "                .then(function (stream) {\n",
    "                    video.srcObject = stream;\n",
    "                })\n",
    "                .catch(function (error) {\n",
    "                    console.error(\"Could not access webcam: \", error);\n",
    "                    document.querySelector('.webcam-area p').textContent = \n",
    "                        \"Could not access webcam. Please check permissions.\";\n",
    "                });\n",
    "        }\n",
    "        \n",
    "        // File upload preview\n",
    "        fileInput.addEventListener('change', function() {\n",
    "            const file = this.files[0];\n",
    "            if (file) {\n",
    "                const reader = new FileReader();\n",
    "                reader.onload = function(e) {\n",
    "                    preview.src = e.target.result;\n",
    "                    preview.style.display = 'block';\n",
    "                    uploadedImage = e.target.result;\n",
    "                }\n",
    "                reader.readAsDataURL(file);\n",
    "            }\n",
    "        });\n",
    "        \n",
    "        // Upload area drag and drop\n",
    "        const uploadArea = document.querySelector('.upload-area');\n",
    "        \n",
    "        uploadArea.addEventListener('dragover', function(e) {\n",
    "            e.preventDefault();\n",
    "            this.style.borderColor = '#4CAF50';\n",
    "        });\n",
    "        \n",
    "        uploadArea.addEventListener('dragleave', function(e) {\n",
    "            e.preventDefault();\n",
    "            this.style.borderColor = '#ccc';\n",
    "        });\n",
    "        \n",
    "        uploadArea.addEventListener('drop', function(e) {\n",
    "            e.preventDefault();\n",
    "            this.style.borderColor = '#ccc';\n",
    "            \n",
    "            const file = e.dataTransfer.files[0];\n",
    "            if (file && file.type.match('image.*')) {\n",
    "                fileInput.files = e.dataTransfer.files;\n",
    "                const reader = new FileReader();\n",
    "                reader.onload = function(e) {\n",
    "                    preview.src = e.target.result;\n",
    "                    preview.style.display = 'block';\n",
    "                    uploadedImage = e.target.result;\n",
    "                }\n",
    "                reader.readAsDataURL(file);\n",
    "            }\n",
    "        });\n",
    "        \n",
    "        // Capture button\n",
    "        captureButton.addEventListener('click', function() {\n",
    "            const context = canvas.getContext('2d');\n",
    "            canvas.width = video.videoWidth;\n",
    "            canvas.height = video.videoHeight;\n",
    "            context.drawImage(video, 0, 0, canvas.width, canvas.height);\n",
    "            capturedImage = canvas.toDataURL('image/png');\n",
    "            predictButton.disabled = false;\n",
    "        });\n",
    "        \n",
    "        // Upload button\n",
    "        uploadButton.addEventListener('click', function() {\n",
    "            if (uploadedImage) {\n",
    "                predictBMI(uploadedImage, 'upload');\n",
    "            } else {\n",
    "                alert('Please upload an image first');\n",
    "            }\n",
    "        });\n",
    "        \n",
    "        // Predict button (webcam)\n",
    "        predictButton.addEventListener('click', function() {\n",
    "            if (capturedImage) {\n",
    "                predictBMI(capturedImage, 'webcam');\n",
    "            } else {\n",
    "                alert('Please capture an image first');\n",
    "            }\n",
    "        });\n",
    "        \n",
    "        // Predict BMI function\n",
    "        function predictBMI(imageData, source) {\n",
    "            // Remove data URL prefix\n",
    "            const base64Image = imageData.split(',')[1];\n",
    "            \n",
    "            // Show loading state\n",
    "            results.style.display = 'block';\n",
    "            bmiValue.textContent = 'Calculating...';\n",
    "            bmiCategory.textContent = '';\n",
    "            bmiInfo.textContent = '';\n",
    "            \n",
    "            // Send to API\n",
    "            fetch('/predict', {\n",
    "                method: 'POST',\n",
    "                headers: {\n",
    "                    'Content-Type': 'application/json'\n",
    "                },\n",
    "                body: JSON.stringify({\n",
    "                    image: base64Image,\n",
    "                    source: source\n",
    "                })\n",
    "            })\n",
    "            .then(response => response.json())\n",
    "            .then(data => {\n",
    "                if (data.error) {\n",
    "                    bmiValue.textContent = 'Error';\n",
    "                    bmiInfo.textContent = data.error;\n",
    "                } else {\n",
    "                    bmiValue.textContent = data.bmi.toFixed(2);\n",
    "                    bmiCategory.textContent = data.category;\n",
    "                    \n",
    "                    // Add BMI explanation\n",
    "                    let infoText = '';\n",
    "                    switch (data.category) {\n",
    "                        case 'Underweight':\n",
    "                            infoText = 'BMI less than 18.5 indicates underweight. This may be associated with certain health issues.';\n",
    "                            break;\n",
    "                        case 'Normal weight':\n",
    "                            infoText = 'BMI between 18.5 and 24.9 indicates a healthy weight for most adults.';\n",
    "                            break;\n",
    "                        case 'Overweight':\n",
    "                            infoText = 'BMI between 25 and 29.9 indicates overweight. This may increase risk for certain diseases.';\n",
    "                            break;\n",
    "                        case 'Obesity':\n",
    "                            infoText = 'BMI of 30 or higher indicates obesity. This increases risk for many health conditions.';\n",
    "                            break;\n",
    "                    }\n",
    "                    bmiInfo.textContent = infoText;\n",
    "                }\n",
    "            })\n",
    "            .catch(error => {\n",
    "                console.error('Error:', error);\n",
    "                bmiValue.textContent = 'Error';\n",
    "                bmiInfo.textContent = 'Failed to process the image. Please try again.';\n",
    "            });\n",
    "        }\n",
    "    </script>\n",
    "</body>\n",
    "</html>\n",
    "        ''')\n",
    "\n",
    "# Flask routes\n",
    "@app.route('/')\n",
    "def index():\n",
    "    \"\"\"Render the main page\"\"\"\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    \"\"\"API endpoint for BMI prediction\"\"\"\n",
    "    try:\n",
    "        data = request.json\n",
    "        base64_image = data.get('image')\n",
    "        source = data.get('source', 'unknown')\n",
    "        \n",
    "        if not base64_image:\n",
    "            return jsonify({'error': 'No image provided'})\n",
    "        \n",
    "        # Preprocess the image\n",
    "        processed_image = preprocess_base64_image(base64_image)\n",
    "        \n",
    "        if processed_image is None:\n",
    "            return jsonify({'error': 'Could not process the image'})\n",
    "        \n",
    "        # Make prediction\n",
    "        model = app.config['model']\n",
    "        predicted_bmi = float(predict_bmi(model, processed_image))\n",
    "        \n",
    "        # Determine BMI category\n",
    "        category = 'Unknown'\n",
    "        if predicted_bmi < 18.5:\n",
    "            category = 'Underweight'\n",
    "        elif 18.5 <= predicted_bmi < 25:\n",
    "            category = 'Normal weight'\n",
    "        elif 25 <= predicted_bmi < 30:\n",
    "            category = 'Overweight'\n",
    "        else:\n",
    "            category = 'Obesity'\n",
    "        \n",
    "        return jsonify({\n",
    "            'bmi': predicted_bmi,\n",
    "            'category': category,\n",
    "            'source': source\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)})\n",
    "\n",
    "# Main function to run the application\n",
    "def main():\n",
    "    \"\"\"Main function to prepare the model and run the app\"\"\"\n",
    "    print(\"Loading and preprocessing data...\")\n",
    "    \n",
    "    # Create templates\n",
    "    create_templates()\n",
    "    \n",
    "    # Check if model already exists\n",
    "    if os.path.exists(MODEL_PATH):\n",
    "        print(f\"Loading existing model from {MODEL_PATH}\")\n",
    "        model = load_model(MODEL_PATH, compile=True)\n",
    "    else:\n",
    "        # Load and preprocess the dataset\n",
    "        X, y = load_data(DATA_PATH, IMAGE_PATH)\n",
    "        \n",
    "        if len(X) == 0:\n",
    "            raise ValueError(\"No valid images found. Please check the data paths.\")\n",
    "        \n",
    "        print(f\"Loaded {len(X)} images for training\")\n",
    "        \n",
    "        # Create and train the model\n",
    "        print(\"Creating and training the model...\")\n",
    "        model = create_model()\n",
    "        history = train_model(X, y, model)\n",
    "        \n",
    "        # Save the model\n",
    "        print(f\"Saving model to {MODEL_PATH}\")\n",
    "        model.save(MODEL_PATH)\n",
    "        \n",
    "        # Save training history plot\n",
    "        save_training_plot(history)\n",
    "    \n",
    "    # Store the model in the app config\n",
    "    app.config['model'] = model\n",
    "    \n",
    "    # Run the Flask app\n",
    "    print(\"Starting the web server...\")\n",
    "    app.run(debug=False, host='0.0.0.0', port=5000)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
